{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Majority Baseline vs Logistic Regression"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["import numpy as np\n", "from pathlib import Path\n"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["DATA_PATH = Path('diabetes_012_health_indicators_BRFSS2015.csv')\n", "\n", "raw = np.loadtxt(DATA_PATH, delimiter=',', skiprows=1)\n", "X = raw[:, 1:]\n", "y = (raw[:, 0] > 0).astype(float)\n", "\n", "print(f'Total samples: {len(X)} | Features: {X.shape[1]}')\n", "print(f'Positive class share: {y.mean():.3f}')\n"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["rng = np.random.default_rng(42)\n", "indices = np.arange(len(X))\n", "rng.shuffle(indices)\n", "\n", "n = len(indices)\n", "train_end = int(0.6 * n)\n", "val_end = int(0.8 * n)\n", "\n", "train_idx = indices[:train_end]\n", "val_idx = indices[train_end:val_end]\n", "test_idx = indices[val_end:]\n", "\n", "X_train, X_val, X_test = X[train_idx], X[val_idx], X[test_idx]\n", "y_train, y_val, y_test = y[train_idx], y[val_idx], y[test_idx]\n", "\n", "mean = X_train.mean(axis=0)\n", "std = X_train.std(axis=0)\n", "std[std == 0] = 1.0\n", "\n", "X_train = (X_train - mean) / std\n", "X_val = (X_val - mean) / std\n", "X_test = (X_test - mean) / std\n", "\n", "print(f'Train size: {len(X_train)}, Val size: {len(X_val)}, Test size: {len(X_test)}')\n"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["neg = np.sum(y_train == 0)\n", "pos = len(y_train) - neg\n", "majority_class = 1 if pos > neg else 0\n", "\n", "y_test_majority = np.full_like(y_test, majority_class)\n", "majority_acc = (y_test_majority == y_test).mean()\n", "\n", "print(f'Majority class (train split): {majority_class}')\n", "print(f'Majority baseline test accuracy: {majority_acc:.4f}')\n"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["class LogisticRegressionGD:\n", "    def __init__(self, lr=0.05, epochs=200, reg=0.0):\n", "        self.lr = lr\n", "        self.epochs = epochs\n", "        self.reg = reg\n", "        self.w = None\n", "        self.b = 0.0\n", "\n", "    @staticmethod\n", "    def _sigmoid(z):\n", "        return 1.0 / (1.0 + np.exp(-z))\n", "\n", "    def fit(self, X, y):\n", "        n_samples, n_features = X.shape\n", "        self.w = np.zeros(n_features)\n", "\n", "        for _ in range(self.epochs):\n", "            linear = X @ self.w + self.b\n", "            preds = self._sigmoid(linear)\n", "            error = preds - y\n", "\n", "            grad_w = (X.T @ error) / n_samples + self.reg * self.w\n", "            grad_b = error.mean()\n", "\n", "            self.w -= self.lr * grad_w\n", "            self.b -= self.lr * grad_b\n", "        return self\n", "\n", "    def predict_proba(self, X):\n", "        return self._sigmoid(X @ self.w + self.b)\n", "\n", "    def predict(self, X, threshold=0.5):\n", "        return (self.predict_proba(X) >= threshold).astype(int)\n"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["learning_rates = [0.03, 0.05]\n", "regs = [0.0, 0.001]\n", "epochs_list = [200, 400]\n", "\n", "best_val_acc = -1.0\n", "best_params = None\n", "best_model = None\n", "\n", "print('Running compact grid search for logistic regression...')\n", "for lr in learning_rates:\n", "    for reg in regs:\n", "        for epochs in epochs_list:\n", "            model = LogisticRegressionGD(lr=lr, reg=reg, epochs=epochs)\n", "            model.fit(X_train, y_train)\n", "            val_preds = model.predict(X_val)\n", "            val_acc = (val_preds == y_val).mean()\n", "            print(f'lr={lr:.3f}, reg={reg:.4f}, epochs={epochs} -> val acc={val_acc:.4f}')\n", "            if val_acc > best_val_acc:\n", "                best_val_acc = val_acc\n", "                best_params = (lr, reg, epochs)\n", "                best_model = model\n", "\n", "print('\nBest hyperparameters by validation accuracy:')\n", "print(f'lr={best_params[0]:.3f}, reg={best_params[1]:.4f}, epochs={best_params[2]}')\n", "print(f'Validation accuracy: {best_val_acc:.4f}')\n", "\n", "val_proba = best_model.predict_proba(X_val)\n", "thresholds = np.linspace(0.3, 0.7, 21)\n", "best_thresh = 0.5\n", "best_thresh_acc = -1.0\n", "\n", "for t in thresholds:\n", "    preds_t = (val_proba >= t).astype(int)\n", "    acc_t = (preds_t == y_val).mean()\n", "    if acc_t > best_thresh_acc:\n", "        best_thresh_acc = acc_t\n", "        best_thresh = t\n", "\n", "print(f'Best threshold on validation set: {best_thresh:.3f} (val acc={best_thresh_acc:.4f})')\n", "\n", "train_preds = best_model.predict(X_train, threshold=best_thresh)\n", "val_preds = best_model.predict(X_val, threshold=best_thresh)\n", "test_preds = best_model.predict(X_test, threshold=best_thresh)\n", "\n", "train_acc = (train_preds == y_train).mean()\n", "val_acc = (val_preds == y_val).mean()\n", "logistic_test_acc = (test_preds == y_test).mean()\n", "\n", "print('\nLogistic regression accuracy with tuned threshold:')\n", "print(f'Train: {train_acc:.4f}')\n", "print(f'Val  : {val_acc:.4f}')\n", "print(f'Test : {logistic_test_acc:.4f}')\n"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["print('--- Summary ---')\n", "print(f'Majority baseline test accuracy: {majority_acc:.4f}')\n", "print(f'Logistic regression test accuracy (threshold={best_thresh:.3f}): {logistic_test_acc:.4f}')\n"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.x"}}, "nbformat": 4, "nbformat_minor": 5}